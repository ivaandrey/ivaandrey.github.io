
## Gaze Direction Estimation ##


Gaze direction estimation is the process of determining where a person is looking based on images or video frames. Itâ€™s widely used in applications such as driver monitoring systems, virtual and augmented reality, human-computer interaction, and medical diagnostics.

<div style="text-align: center;">
  <img src="images/gaze_estimation_page_driver_image.png?raw=true" width="40%" height="40%"/>
</div>

Gaze estimation techniques can be broadly categorized into:

+ **Model-based methods:** relies on geometric and anatomical models of the human eye and head 
+ **Appearance-based methods:** Learn gaze patterns from raw image data using deep learning or machine learning models to directly learn gaze patterns from raw images. These methods treat gaze estimation as a regression or classification problem.
  
The gaze estimation activity I lead involves managing a team focused on an **appearance-based approach**, where I oversee the research, development, optimization, and deployment of deep learning models for gaze tracking. My responsibilities span technical leadership, encompassing algorithm design, model training, dataset curation, performance evaluation, deployment, and integration into SDKs to ensure robust and accurate gaze estimation for driver monitoring systems (DMS) applications and human-computer interaction (HCI). I lead the end-to-end development pipeline, from researching and implementing state-of-the-art deep learning models to optimizing them for efficiency, scalability, and real-time deployment.

